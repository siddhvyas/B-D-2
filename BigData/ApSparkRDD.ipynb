{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ6GJQ4mSIwS"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[1]\") \\\n",
        "                    .appName('SparkByExamples.com') \\\n",
        "                    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(\"Z\", 1),(\"A\", 20),(\"B\", 30),(\"C\", 40),(\"B\", 30),(\"B\", 60)]\n",
        "inputRDD = spark.sparkContext.parallelize(data)"
      ],
      "metadata": {
        "id": "e8ww7MCLSNpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listRdd = spark.sparkContext.parallelize([1,2,3,4,5,3,2])"
      ],
      "metadata": {
        "id": "1pxN1Qg5S1Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputRDD.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuYng6K_TJd4",
        "outputId": "931a0054-30b5-4e47-fe8d-baf66f6ef3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collRDD = inputRDD.collect()\n",
        "for row in collRDD:\n",
        "    print(row[0] + \",\" +str(row[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffOPCJ1bUazG",
        "outputId": "81900ebc-c32e-4b09-e135-78f1423ba54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z,1\n",
            "A,20\n",
            "B,30\n",
            "C,40\n",
            "B,30\n",
            "B,60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coll1RDD = listRdd.collect()\n",
        "for row in coll1RDD:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSj0My3TUjOX",
        "outputId": "62bd7e9a-8300-490b-bc58-166621793a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "3\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#aggregate\n",
        "seqOp = (lambda x, y: x + y)\n",
        "combOp = (lambda x, y: x + y)\n",
        "agg=listRdd.aggregate(0, seqOp, combOp)\n",
        "print(agg) # output 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp30zDUjVM13",
        "outputId": "0aeba838-c621-426b-d4ba-86efcfb243bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\n",
        "broadcastStates = spark.sparkContext.broadcast(states)\n",
        "\n",
        "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
        "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
        "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
        "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
        "  ]\n",
        "\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "\n",
        "def state_convert(code):\n",
        "    return broadcastStates.value[code]\n",
        "\n",
        "result = rdd.map(lambda x: (x[0],x[1],x[2],state_convert(x[3]))).collect()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiowBMR4VQIm",
        "outputId": "27da31fb-90da-4584-ab07-c95de16ec755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('James', 'Smith', 'USA', 'California'), ('Michael', 'Rose', 'USA', 'New York'), ('Robert', 'Williams', 'USA', 'California'), ('Maria', 'Jones', 'USA', 'Florida')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"Project Gutenberg’s\",\n",
        "        \"Alice’s Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\",\n",
        "        \"Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\"]\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "\n",
        "for element in rdd.collect():\n",
        "    print(element)\n",
        "\n",
        "#Flatmap\n",
        "rdd2=rdd.flatMap(lambda x: x.split(\" \"))\n",
        "for element in rdd2.collect():\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKM3hQ13VwrX",
        "outputId": "dd07a4a9-cee6-4308-efd8-330c50d8465c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project Gutenberg’s\n",
            "Alice’s Adventures in Wonderland\n",
            "Project Gutenberg’s\n",
            "Adventures in Wonderland\n",
            "Project Gutenberg’s\n",
            "Project\n",
            "Gutenberg’s\n",
            "Alice’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"Project\",\n",
        "\"Gutenberg’s\",\n",
        "\"Alice’s\",\n",
        "\"Adventures\",\n",
        "\"in\",\n",
        "\"Wonderland\",\n",
        "\"Project\",\n",
        "\"Gutenberg’s\",\n",
        "\"Adventures\",\n",
        "\"in\",\n",
        "\"Wonderland\",\n",
        "\"Project\",\n",
        "\"Gutenberg’s\"]\n",
        "\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "\n",
        "rdd2=rdd.map(lambda x: (x,1))\n",
        "for element in rdd2.collect():\n",
        "    print(element)\n",
        "\n",
        "data = [('James','Smith','M',30),\n",
        "  ('Anna','Rose','F',41),\n",
        "  ('Robert','Williams','M',62),\n",
        "]\n",
        "\n",
        "columns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)\n",
        "df.show()\n",
        "\n",
        "rdd2=df.rdd.map(lambda x:\n",
        "    (x[0]+\",\"+x[1],x[2],x[3]*2)\n",
        "    )\n",
        "df2=rdd2.toDF([\"name\",\"gender\",\"new_salary\"]   )\n",
        "df2.show()\n",
        "\n",
        "\n",
        "#Referring Column Names\n",
        "rdd2=df.rdd.map(lambda x:\n",
        "    (x[\"firstname\"]+\",\"+x[\"lastname\"],x[\"gender\"],x[\"salary\"]*2)\n",
        "    )\n",
        "\n",
        "\n",
        "#Referring Column Names\n",
        "rdd2=df.rdd.map(lambda x:\n",
        "    (x.firstname+\",\"+x.lastname,x.gender,x.salary*2)\n",
        "    )\n",
        "\n",
        "\n",
        "def func1(x):\n",
        "    firstName=x.firstname\n",
        "    lastName=x.lastname\n",
        "    name=firstName+\",\"+lastName\n",
        "    gender=x.gender.lower()\n",
        "    salary=x.salary*2\n",
        "    return (name,gender,salary)\n",
        "\n",
        "rdd2=df.rdd.map(lambda x: func1(x)).toDF().show()\n",
        "rdd2=df.rdd.map(func1).toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRSwWLJiWBPe",
        "outputId": "602b73a8-dee8-42f9-8f17-bd8c5d17ab0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Alice’s', 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "+---------+--------+------+------+\n",
            "|firstname|lastname|gender|salary|\n",
            "+---------+--------+------+------+\n",
            "|    James|   Smith|     M|    30|\n",
            "|     Anna|    Rose|     F|    41|\n",
            "|   Robert|Williams|     M|    62|\n",
            "+---------+--------+------+------+\n",
            "\n",
            "+---------------+------+----------+\n",
            "|           name|gender|new_salary|\n",
            "+---------------+------+----------+\n",
            "|    James,Smith|     M|        60|\n",
            "|      Anna,Rose|     F|        82|\n",
            "|Robert,Williams|     M|       124|\n",
            "+---------------+------+----------+\n",
            "\n",
            "+---------------+---+---+\n",
            "|             _1| _2| _3|\n",
            "+---------------+---+---+\n",
            "|    James,Smith|  m| 60|\n",
            "|      Anna,Rose|  f| 82|\n",
            "|Robert,Williams|  m|124|\n",
            "+---------------+---+---+\n",
            "\n",
            "+---------------+---+---+\n",
            "|             _1| _2| _3|\n",
            "+---------------+---+---+\n",
            "|    James,Smith|  m| 60|\n",
            "|      Anna,Rose|  f| 82|\n",
            "|Robert,Williams|  m|124|\n",
            "+---------------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [('Project', 1),\n",
        "('Gutenberg’s', 1),\n",
        "('Alice’s', 1),\n",
        "('Adventures', 1),\n",
        "('in', 1),\n",
        "('Wonderland', 1),\n",
        "('Project', 1),\n",
        "('Gutenberg’s', 1),\n",
        "('Adventures', 1),\n",
        "('in', 1),\n",
        "('Wonderland', 1),\n",
        "('Project', 1),\n",
        "('Gutenberg’s', 1)]\n",
        "\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "\n",
        "rdd2=rdd.reduceByKey(lambda a,b: a+b)\n",
        "for element in rdd2.collect():\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvqaBPA1W67G",
        "outputId": "9473ad85-f394-4123-a300-afb9e901ff13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Project', 3)\n",
            "('Gutenberg’s', 3)\n",
            "('Alice’s', 1)\n",
            "('Adventures', 2)\n",
            "('in', 2)\n",
            "('Wonderland', 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dept = [(\"Finance\",10),\n",
        "        (\"Marketing\",20),\n",
        "        (\"Sales\",30),\n",
        "        (\"IT\",40)\n",
        "      ]\n",
        "rdd = spark.sparkContext.parallelize(dept)\n",
        "\n",
        "df = rdd.toDF()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQg-roZGXV9V",
        "outputId": "697566f2-d616-430c-a0f4-bf0eb4f93d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50yJ0GMfXuTV",
        "outputId": "6209b53e-2c48-441e-9e65-f75642bb450c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+\n",
            "|_1       |_2 |\n",
            "+---------+---+\n",
            "|Finance  |10 |\n",
            "|Marketing|20 |\n",
            "|Sales    |30 |\n",
            "|IT       |40 |\n",
            "+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deptColumns = [\"dept_name\",\"dept_id\"]\n",
        "df2 = rdd.toDF(deptColumns)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1D3e0hjXymt",
        "outputId": "29aec09e-b17d-45de-f36b-403cbcc06049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show(truncate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDIVRBCeYBmN",
        "outputId": "b89804e9-a8b2-452f-abe2-1911c562488e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|  Finance|     10|\n",
            "|Marketing|     20|\n",
            "|    Sales|     30|\n",
            "|       IT|     40|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
        "deptDF.printSchema()\n",
        "deptDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "565_M_-dYMxU",
        "outputId": "a8d88379-29ae-4c74-dc68-8bf6cdf407f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType\n",
        "deptSchema = StructType([\n",
        "    StructField('dept_name', StringType(), True),\n",
        "    StructField('dept_id', StringType(), True)\n",
        "])\n",
        "\n",
        "deptDF1 = spark.createDataFrame(data=dept, schema = deptSchema)\n",
        "deptDF1.printSchema()\n",
        "deptDF1.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilJKmVPfYO5l",
        "outputId": "ceb0e8c6-d452-48c4-fddf-155ba7432b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: string (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"Project Gutenberg’s\",\n",
        "        \"Alice’s Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\",\n",
        "        \"Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\"]\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "\n",
        "for element in rdd.collect():\n",
        "    print(element)\n",
        "\n",
        "#Flatmap\n",
        "rdd2=rdd.flatMap(lambda x: x.split(\" \"))\n",
        "for element in rdd2.collect():\n",
        "    print(element)\n",
        "#map\n",
        "rdd3=rdd2.map(lambda x: (x,1))\n",
        "for element in rdd3.collect():\n",
        "    print(element)\n",
        "#reduceByKey\n",
        "rdd4=rdd3.reduceByKey(lambda a,b: a+b)\n",
        "for element in rdd4.collect():\n",
        "    print(element)\n",
        "#map\n",
        "rdd5 = rdd4.map(lambda x: (x[1],x[0])).sortByKey()\n",
        "for element in rdd5.collect():\n",
        "    print(element)\n",
        "#filter\n",
        "rdd6 = rdd5.filter(lambda x : 'a' in x[1])\n",
        "for element in rdd6.collect():\n",
        "    print(element)\n",
        "\n",
        "from pyspark.sql.functions import col,expr\n",
        "data=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",3)]\n",
        "spark.createDataFrame(data).toDF(\"date\",\"increment\") \\\n",
        "    .select(col(\"date\"),col(\"increment\"), \\\n",
        "      expr(\"add_months(to_date(date,'yyyy-MM-dd'),cast(increment as int))\").alias(\"inc_date\")) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LSJyR5bYeNt",
        "outputId": "82f6b296-4452-4468-a183-438ab95088c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project Gutenberg’s\n",
            "Alice’s Adventures in Wonderland\n",
            "Project Gutenberg’s\n",
            "Adventures in Wonderland\n",
            "Project Gutenberg’s\n",
            "Project\n",
            "Gutenberg’s\n",
            "Alice’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Alice’s', 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Project', 3)\n",
            "('Gutenberg’s', 3)\n",
            "('Alice’s', 1)\n",
            "('Adventures', 2)\n",
            "('in', 2)\n",
            "('Wonderland', 2)\n",
            "(1, 'Alice’s')\n",
            "(2, 'Adventures')\n",
            "(2, 'in')\n",
            "(2, 'Wonderland')\n",
            "(3, 'Project')\n",
            "(3, 'Gutenberg’s')\n",
            "(2, 'Wonderland')\n",
            "+----------+---------+----------+\n",
            "|      date|increment|  inc_date|\n",
            "+----------+---------+----------+\n",
            "|2019-01-23|        1|2019-02-23|\n",
            "|2019-06-24|        2|2019-08-24|\n",
            "|2019-09-20|        3|2019-12-20|\n",
            "+----------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.textFile(\"/content/sample_data/data.txt\")\n",
        "\n",
        "for element in rdd.collect():\n",
        "    print(element)\n",
        "\n",
        "#Flatmap\n",
        "rdd2=rdd.flatMap(lambda x: x.split(\" \"))\n",
        "for element in rdd2.collect():\n",
        "    print(element)\n",
        "#map\n",
        "rdd3=rdd2.map(lambda x: (x,1))\n",
        "for element in rdd3.collect():\n",
        "    print(element)\n",
        "#reduceByKey\n",
        "rdd4=rdd3.reduceByKey(lambda a,b: a+b)\n",
        "for element in rdd4.collect():\n",
        "    print(element)\n",
        "#map\n",
        "rdd5 = rdd4.map(lambda x: (x[1],x[0])).sortByKey()\n",
        "for element in rdd5.collect():\n",
        "    print(element)\n",
        "#filter\n",
        "rdd6 = rdd5.filter(lambda x : 'a' in x[1])\n",
        "for element in rdd6.collect():\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFbpGt9OY03E",
        "outputId": "de9d3576-025a-404a-8d9f-5fb5c9917663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project Gutenberg’s\n",
            "Alice’s Adventures in Wonderland\n",
            "Project Gutenberg’s\n",
            "Adventures in Wonderland\n",
            "Project Gutenberg’s\n",
            "Project\n",
            "Gutenberg’s\n",
            "Alice’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Alice’s', 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Project', 3)\n",
            "('Gutenberg’s', 3)\n",
            "('Alice’s', 1)\n",
            "('Adventures', 2)\n",
            "('in', 2)\n",
            "('Wonderland', 2)\n",
            "(1, 'Alice’s')\n",
            "(2, 'Adventures')\n",
            "(2, 'in')\n",
            "(2, 'Wonderland')\n",
            "(3, 'Project')\n",
            "(3, 'Gutenberg’s')\n",
            "(2, 'Wonderland')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIkI3IobZ5bM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}